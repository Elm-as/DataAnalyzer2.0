# DataAnalyzer 2.0

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“Š Description

DataAnalyzer 2.0 est une plateforme no-code d'analyse de donnÃ©es professionnelle, Ã©quivalente Ã  un notebook Python complet (pandas, scikit-learn, statsmodels) mais avec une interface graphique intuitive.

### âœ¨ FonctionnalitÃ©s principales

- **Chargement de donnÃ©es** : CSV, Excel, JSON
- **Profiling automatique** : DÃ©tection de types, mÃ©triques de qualitÃ©
- **Analyses exploratoires (EDA)** : Statistiques, corrÃ©lations, distributions, outliers
- **ModÃ©lisation ML** : RÃ©gression, classification avec validation scientifique stricte
- **Export complet** : Rapports HTML, code Python, modÃ¨les, donnÃ©es
- **PÃ©dagogie intÃ©grÃ©e** : Explications Ã  chaque Ã©tape

### ğŸ¯ RÃ¨gles scientifiques strictes

#### RÃˆGLE 1 : SÃ©paration cible/features
La variable cible ne peut **JAMAIS** Ãªtre utilisÃ©e comme variable explicative.

```python
# âŒ INTERDIT
X = df[features + [target]]

# âœ… CORRECT
X = df[features]
y = df[target]
```

#### RÃˆGLE 2 : CohÃ©rence des analyses
- Classification â†’ Cible catÃ©gorielle â†’ Accuracy, F1, ROC-AUC
- RÃ©gression â†’ Cible numÃ©rique â†’ RÂ², RMSE, MAE

#### RÃˆGLE 3 : Transparence totale
Tous les paramÃ¨tres sont affichÃ©s et personnalisables.

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- pip

### Ã‰tapes

```bash
# Cloner le repository
git clone https://github.com/Elm-as/DataAnalyzer2.0.git
cd DataAnalyzer2.0

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer l'application
streamlit run app.py
```

## ğŸ“‚ Structure du projet

```
DataAnalyzer2.0/
â”œâ”€â”€ app.py                    # Point d'entrÃ©e Streamlit
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Titanic-Dataset.csv   # Dataset d'exemple
â”‚   â””â”€â”€ uploads/              # Fichiers utilisateurs
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ data_loader.py        # Chargement fichiers
â”‚   â”œâ”€â”€ data_profiler.py      # Profiling automatique
â”‚   â”œâ”€â”€ eda.py               # Analyses exploratoires
â”‚   â”œâ”€â”€ ml_models.py         # ModÃ¨les ML
â”‚   â”œâ”€â”€ time_series.py       # SÃ©ries temporelles
â”‚   â”œâ”€â”€ text_analysis.py     # Analyse texte
â”‚   â”œâ”€â”€ visualizations.py    # Graphiques
â”‚   â””â”€â”€ export.py            # Export rapports
â””â”€â”€ utils/
    â”œâ”€â”€ validation.py        # Validation scientifique
    â””â”€â”€ explanations.py      # Textes pÃ©dagogiques
```

## ğŸ“ Utilisation

### 1. Chargement des donnÃ©es

- Uploader un fichier CSV/Excel/JSON
- Ou utiliser le dataset Titanic prÃ©-chargÃ©

### 2. SÃ©lection de la cible

- Choisir la variable Ã  prÃ©dire
- Le systÃ¨me dÃ©tecte automatiquement le type (rÃ©gression/classification)
- **La cible est automatiquement exclue des features**

### 3. Exploration (EDA)

- Statistiques descriptives
- CorrÃ©lations (Pearson/Spearman)
- Distributions avec KDE
- DÃ©tection d'anomalies (IQR)
- Analyse catÃ©gorielle

### 4. ModÃ©lisation

- **RÃ©gression** : Linear, Ridge, Lasso, Random Forest, XGBoost, LightGBM
- **Classification** : Logistic, Random Forest, XGBoost, LightGBM
- MÃ©triques automatiques selon le type
- Feature importance
- Validation train/test

### 5. Export

- Rapport HTML professionnel
- Code Python reproductible
- ModÃ¨les entraÃ®nÃ©s (pickle)
- DonnÃ©es transformÃ©es
- Session complÃ¨te (JSON)

## ğŸ“– Exemple avec Titanic

```python
# 1. Charger Titanic-Dataset.csv
# 2. SÃ©lectionner Survived comme cible
#    â†’ Type dÃ©tectÃ© : Classification binaire
# 3. Features auto-sÃ©lectionnÃ©es (sans Survived)
# 4. EntraÃ®ner Random Forest
#    â†’ Accuracy ~82%
#    â†’ Features importantes : Sex, Age, Pclass
```

## ğŸ§ª Tests de validation

Le systÃ¨me passe ces tests :

1. âœ… Dataset IRIS â†’ Species = cible â†’ Classification uniquement
2. âœ… Dataset Titanic â†’ Survived = cible â†’ Jamais dans features
3. âœ… SÃ©paration stricte X/y â†’ Validation scientifique
4. âœ… MÃ©triques cohÃ©rentes avec le type de problÃ¨me

## ğŸ› ï¸ Technologies

- **Frontend/Backend** : Streamlit
- **Data Processing** : pandas, numpy
- **ML** : scikit-learn, xgboost, lightgbm
- **Stats** : scipy, statsmodels
- **Visualisation** : matplotlib, seaborn, plotly

## ğŸ“Š Captures d'Ã©cran

*(Ã€ ajouter aprÃ¨s le premier dÃ©ploiement)*

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Veuillez :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ License

MIT License - voir le fichier LICENSE pour plus de dÃ©tails

## ğŸ‘¤ Auteur

Elm-as

## ğŸ™ Remerciements

- Dataset Titanic : [Kaggle](https://www.kaggle.com/c/titanic)
- Streamlit pour le framework
- CommunautÃ© open-source

---

**DataAnalyzer 2.0** - Analyse de donnÃ©es accessible Ã  tous ğŸ“Š
